import pandas as pd
import numpy as np
from typing import Dict, List, Any
from collections import defaultdict, Counter

from config import ml_config
from utils.logger import setup_logger, flush_log

logger = setup_logger(__name__)


class DefectAnalyzer:
    """ë¶ˆëŸ‰ ë°ì´í„° ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        pass

    def analyze_defect_types(
        self, data: pd.DataFrame, label_encoders: Dict = None
    ) -> List[Dict[str, Any]]:
        """ë¶ˆëŸ‰ ìœ í˜•ë³„ ë¶„ì„"""
        logger.info("ğŸ“Š ë¶ˆëŸ‰ ìœ í˜• ë¶„ì„ ì¤‘...")

        # ëŒ€ë¶„ë¥˜ë³„ ë¶ˆëŸ‰ ì¹´ìš´íŠ¸
        defect_types = data.groupby("ëŒ€ë¶„ë¥˜").size().reset_index(name="count")

        # ë¼ë²¨ ë””ì½”ë”© (ë¼ë²¨ ì¸ì½”ë”ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        if label_encoders and "ëŒ€ë¶„ë¥˜" in label_encoders:
            defect_types["ëŒ€ë¶„ë¥˜"] = label_encoders["ëŒ€ë¶„ë¥˜"].inverse_transform(
                defect_types["ëŒ€ë¶„ë¥˜"]
            )

        # ë¹„ìœ¨ ê³„ì‚°
        total_defects = defect_types["count"].sum()
        defect_analysis = []

        for _, row in defect_types.iterrows():
            defect_analysis.append(
                {
                    "category": row["ëŒ€ë¶„ë¥˜"],
                    "count": int(row["count"]),
                    "percentage": round(row["count"] / total_defects * 100, 2),
                }
            )

        # ì¹´ìš´íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        defect_analysis.sort(key=lambda x: x["count"], reverse=True)

        logger.info(f"âœ… ë¶ˆëŸ‰ ìœ í˜• ë¶„ì„ ì™„ë£Œ: {len(defect_analysis)}ê°œ ìœ í˜•")
        for analysis in defect_analysis:
            logger.info(
                f"  - {analysis['category']}: {analysis['count']}ê±´ ({analysis['percentage']}%)"
            )

        flush_log(logger)
        return defect_analysis

    def generate_recent_defects(
        self,
        data: pd.DataFrame,
        label_encoders: Dict = None,
        production_weights: Dict[str, float] = None,
        hours: int = 24,
    ) -> List[Dict[str, Any]]:
        """ìµœê·¼ ë¶ˆëŸ‰ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ ìƒì„± (ë°ì´í„° ì¶•ì ìš©)"""
        logger.info(f"ğŸ“ˆ ìµœê·¼ {hours}ì‹œê°„ ë¶ˆëŸ‰ ë°ì´í„° ìƒì„± ì¤‘...")

        recent_data = []

        for i in range(hours):
            # ìƒì‚°ëŸ‰ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìƒ˜í”Œë§
            if production_weights and label_encoders:
                # ì œí’ˆëª… ê°€ì¤‘ì¹˜ ë§¤í•‘
                data["production_weight"] = data["ì œí’ˆëª…"].apply(
                    lambda x: self._get_production_weight(
                        x, production_weights, label_encoders
                    )
                )
                sample = data.sample(
                    1, weights="production_weight", random_state=42 + i
                ).iloc[0]
            else:
                sample = data.sample(1, random_state=42 + i).iloc[0]

            # ë°ì´í„° êµ¬ì„± (ë¼ë²¨ ì¸ì½”ë”ê°€ ìˆëŠ” ê²½ìš° ë””ì½”ë”©, ì—†ìœ¼ë©´ ì›ë³¸ ê°’ ì‚¬ìš©)
            recent_data.append(
                {
                    "ì œí’ˆëª…": (
                        label_encoders["ì œí’ˆëª…"].inverse_transform([sample["ì œí’ˆëª…"]])[
                            0
                        ]
                        if label_encoders
                        else sample["ì œí’ˆëª…"]
                    ),
                    "ë¶€í’ˆëª…": (
                        label_encoders["ë¶€í’ˆëª…"].inverse_transform([sample["ë¶€í’ˆëª…"]])[
                            0
                        ]
                        if label_encoders
                        else sample["ë¶€í’ˆëª…"]
                    ),
                    "ê²€ì¶œë‹¨ê³„": (
                        label_encoders["ê²€ì¶œë‹¨ê³„"].inverse_transform(
                            [sample["ê²€ì¶œë‹¨ê³„"]]
                        )[0]
                        if label_encoders
                        else sample["ê²€ì¶œë‹¨ê³„"]
                    ),
                    "ëŒ€ë¶„ë¥˜": (
                        label_encoders["ëŒ€ë¶„ë¥˜"].inverse_transform([sample["ëŒ€ë¶„ë¥˜"]])[
                            0
                        ]
                        if label_encoders
                        else sample["ëŒ€ë¶„ë¥˜"]
                    ),
                    "ì¤‘ë¶„ë¥˜": (
                        label_encoders["ì¤‘ë¶„ë¥˜"].inverse_transform([sample["ì¤‘ë¶„ë¥˜"]])[
                            0
                        ]
                        if label_encoders
                        else sample["ì¤‘ë¶„ë¥˜"]
                    ),
                    "timestamp": pd.Timestamp.now() - pd.Timedelta(hours=hours - i),
                    "keywords": sample["keywords"],
                }
            )

        logger.info(f"âœ… {len(recent_data)}ê±´ì˜ ìµœê·¼ ë¶ˆëŸ‰ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        flush_log(logger)

        return recent_data

    def analyze_top_defects(
        self, recent_data: List[Dict[str, Any]], top_n: int = 5
    ) -> List[tuple]:
        """ì œí’ˆ-ë‹¨ê³„-ë¶€í’ˆë³„ ìƒìœ„ ë¶ˆëŸ‰ ë¶„ì„"""
        logger.info("ğŸ” ìƒìœ„ ë¶ˆëŸ‰ íŒ¨í„´ ë¶„ì„ ì¤‘...")

        product_stage_part_defects = defaultdict(int)

        for defect in recent_data:
            key = f"{defect['ì œí’ˆëª…']} - {defect['ê²€ì¶œë‹¨ê³„']} - {defect['ë¶€í’ˆëª…']}"
            product_stage_part_defects[key] += 1

        # ìƒìœ„ ë¶ˆëŸ‰ íŒ¨í„´ ì¶”ì¶œ
        top_defects = sorted(
            product_stage_part_defects.items(), key=lambda x: x[1], reverse=True
        )[:top_n]

        logger.info(f"âœ… ìƒìœ„ {len(top_defects)}ê°œ ë¶ˆëŸ‰ íŒ¨í„´:")
        for pattern, count in top_defects:
            logger.info(f"  - {pattern}: {count}ê±´")

        flush_log(logger)
        return top_defects

    def generate_suggestions(
        self,
        defect_analysis: List[Dict[str, Any]],
        top_defects: List[tuple],
        top_keywords: List[str],
    ) -> str:
        """ì˜ˆë°© ì¡°ì¹˜ ì œì•ˆ ìƒì„±"""
        logger.info("ğŸ’¡ ì˜ˆë°© ì¡°ì¹˜ ì œì•ˆ ìƒì„± ì¤‘...")

        if not defect_analysis:
            return "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì œì•ˆì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê°€ì¥ ë¹ˆë²ˆí•œ ë¶ˆëŸ‰ ìœ í˜•
        major_defect = max(defect_analysis, key=lambda x: x["count"])
        major_category = major_defect["category"]

        # ìƒìœ„ ë¶ˆëŸ‰ íŒ¨í„´ì—ì„œ ì£¼ìš” ë¶€í’ˆ ì¶”ì¶œ
        top_part = ""
        if top_defects:
            top_part = (
                top_defects[0][0].split(" - ")[2]
                if len(top_defects[0][0].split(" - ")) >= 3
                else ""
            )

        # ìƒìœ„ í‚¤ì›Œë“œ ë¬¸ìì—´
        top_keywords_str = ", ".join(top_keywords[:3])

        # ë¶ˆëŸ‰ ìœ í˜•ë³„ ì œì•ˆ ìƒì„±
        if major_category == "ê¸°êµ¬ì‘ì—…ë¶ˆëŸ‰":
            suggestion = (
                f"{top_part} ê´€ë ¨ ì‘ì—…ì êµìœ¡ ê°•í™”, {top_keywords_str} ê´€ë ¨ ê³µì • ì ê²€"
            )
        elif major_category == "ë¶€í’ˆë¶ˆëŸ‰":
            suggestion = f"{top_part} ë¶€í’ˆ ê³µê¸‰ì‚¬ í’ˆì§ˆ ì ê²€, ëŒ€ì²´ ë¶€í’ˆ ê²€í† "
        elif major_category == "ë„ë©´ë¶ˆëŸ‰":
            suggestion = "ë„ë©´ ê²€í†  í”„ë¡œì„¸ìŠ¤ ê°•í™”, ì„¤ê³„ ê²€ì¦ ì ˆì°¨ ê°œì„ "
        else:
            suggestion = (
                f"{major_category} ê´€ë ¨ ê³µì • ê°œì„ , {top_keywords_str} ìš”ì¸ ì§‘ì¤‘ ê´€ë¦¬"
            )

        logger.info(f"âœ… ì œì•ˆ ìƒì„± ì™„ë£Œ: {suggestion}")
        flush_log(logger)

        return suggestion

    def _get_production_weight(
        self,
        encoded_product: int,
        production_weights: Dict[str, float],
        label_encoders: Dict,
    ) -> float:
        """ì¸ì½”ë”©ëœ ì œí’ˆëª…ì„ ì›ë˜ ì´ë¦„ìœ¼ë¡œ ë³µì›í•˜ì—¬ ìƒì‚°ëŸ‰ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        try:
            product_name = label_encoders["ì œí’ˆëª…"].inverse_transform(
                [encoded_product]
            )[0]
            return production_weights.get(product_name, 0.01)
        except Exception:
            return 0.01

    def create_dashboard_data(
        self,
        predictions: List[Dict],
        defect_analysis: List[Dict[str, Any]],
        top_keywords: List[str],
        suggestion: str,
    ) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œìš© JSON ë°ì´í„° ìƒì„±"""
        logger.info("ğŸ“‹ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì¤‘...")

        # ì˜ˆì¸¡ ë°ì´í„°ì— ì¶”ê°€ ì •ë³´ ë³´ê°•
        enhanced_predictions = []
        for pred in predictions:
            enhanced_pred = pred.copy()

            # ë¶ˆëŸ‰ ìœ í˜• ê²°ì • (ë™ì  ë°©ì‹ìœ¼ë¡œ)
            defect_type = "ê¸°êµ¬ì‘ì—…ë¶ˆëŸ‰"  # ê¸°ë³¸ê°’
            try:
                # ê°€ì¥ ë§ì€ ë¶ˆëŸ‰ ìœ í˜•ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                if defect_analysis and len(defect_analysis) > 0:
                    # ê°€ì¥ ë§ì€ ë¶ˆëŸ‰ ìœ í˜• ì„ íƒ
                    most_common_defect = defect_analysis[0].get(
                        "category", "ê¸°êµ¬ì‘ì—…ë¶ˆëŸ‰"
                    )
                    defect_type = most_common_defect
            except Exception as e:
                logger.warning(f"ë¶ˆëŸ‰ ìœ í˜• ê²°ì • ì¤‘ ì˜¤ë¥˜: {e}")

            enhanced_pred["ë¶ˆëŸ‰ìœ í˜•"] = defect_type

            # ëˆ„ì  ê±´ìˆ˜ (ì˜ˆìƒë¶ˆëŸ‰ë¥  ê¸°ë°˜)
            defect_rate = pred.get("ì˜ˆìƒë¶ˆëŸ‰ë¥ ", 0)
            if defect_rate >= 20:
                enhanced_pred["ëˆ„ì "] = np.random.randint(40, 80)
            elif defect_rate >= 10:
                enhanced_pred["ëˆ„ì "] = np.random.randint(20, 40)
            elif defect_rate >= 5:
                enhanced_pred["ëˆ„ì "] = np.random.randint(10, 20)
            else:
                enhanced_pred["ëˆ„ì "] = np.random.randint(5, 15)

            # ì œì•ˆ ì¶”ê°€
            enhanced_pred["ì œì•ˆ"] = suggestion

            enhanced_predictions.append(enhanced_pred)

        dashboard_data = {
            "predictions": enhanced_predictions,
            "defect_analysis": defect_analysis,
            "top_keywords": top_keywords,
            "suggestion": suggestion,
            "generated_at": pd.Timestamp.now().isoformat(),
            "data_count": len(predictions),
        }

        logger.info(f"âœ… ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(enhanced_predictions)}ê°œ ì˜ˆì¸¡")
        flush_log(logger)

        return dashboard_data
