import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from collections import Counter
from googleapiclient.discovery import build
from google.oauth2.service_account import Credentials
from mecab import MeCab

# from konlpy.tag import Okt # Java ì„¤ì¹˜ ë¬¸ì œë¡œ ë‹¤ì‹œ ì£¼ì„ ì²˜ë¦¬

from config import data_config, sheets_config, KOREAN_STOP_WORDS
from utils.logger import setup_logger, flush_log

logger = setup_logger(__name__)


class DataLoader:
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.data_config = data_config
        self.mecab = MeCab()
        # self.nlp = Okt() # Java ì„¤ì¹˜ ë¬¸ì œë¡œ ë‹¤ì‹œ ì£¼ì„ ì²˜ë¦¬
        self.korean_stop_words = set(KOREAN_STOP_WORDS)

        # ì œí’ˆëª… ë§¤í•‘ (CSV ì œí’ˆëª… -> ìƒì‚°ëŸ‰ ë°ì´í„° ì œí’ˆëª…)
        self.product_name_mapping = {
            "DRAGON AB DUAL": "DRAGON DUAL",
            "DRAGON AB": "DRAGON",
            "DRAGON AB SINGLE": "DRAGON",  # ë§ìŒ!
            "DRAGON LE DUAL": "DRAGON DUAL",
            # GAIA-P, GAIA-P20, GAIA-I SINGLE, WET 1000ì€ ê°œë³„ ëª¨ë¸ë¡œ ìœ ì§€
            # í•„ìš”ì‹œ ì¶”ê°€ ë§¤í•‘ ê·œì¹™
        }

    def normalize_product_name(self, name: str) -> str:
        """ì œí’ˆëª…ì„ ìƒì‚°ëŸ‰ ë°ì´í„°ì™€ ë§¤ì¹­ë˜ë„ë¡ ì •ê·œí™”"""
        return self.product_name_mapping.get(name, name)

    def load_defect_data(self) -> pd.DataFrame:
        """ë¶ˆëŸ‰ ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“Š ë¶ˆëŸ‰ ë°ì´í„° ë¡œë“œ ì¤‘...")
        try:
            data = pd.read_csv(self.data_config.csv_file_path, encoding="utf-8")

            # ë°ì´í„° ê²€ì¦
            missing_cols = [
                col
                for col in self.data_config.required_columns
                if col not in data.columns
            ]
            if missing_cols:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")

            # ì œí’ˆëª… ì •ê·œí™”
            original_product_count = len(data["ì œí’ˆëª…"].unique())
            data["ì œí’ˆëª…"] = data["ì œí’ˆëª…"].apply(self.normalize_product_name)
            new_product_count = len(data["ì œí’ˆëª…"].unique())
            if original_product_count != new_product_count:
                logger.info(
                    f"ì œí’ˆëª… ì •ê·œí™” ì ìš©: {original_product_count} -> {new_product_count}ê°œ"
                )

            # ì œì™¸í•  í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§
            for keyword in self.data_config.exclude_keywords:
                data = data[~data["ë¹„ê³ "].str.contains(keyword, case=False, na=False)]

            # ë¹ˆ ë¶ˆëŸ‰ë‚´ìš© ì œê±°
            data = data[data["ìƒì„¸ë¶ˆëŸ‰ë‚´ìš©"].str.strip() != ""]

            # NaN ê°’ ì²˜ë¦¬ - ì£¼ìš” ì»¬ëŸ¼ë“¤ì˜ NaNì„ "ë¯¸ë¶„ë¥˜"ë¡œ ëŒ€ì²´
            categorical_columns = ["ì œí’ˆëª…", "ë¶€í’ˆëª…", "ê²€ì¶œë‹¨ê³„", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜"]
            for col in categorical_columns:
                if col in data.columns:
                    data[col] = data[col].fillna("ë¯¸ë¶„ë¥˜")

            # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
            data["ë°œìƒì¼"] = pd.to_datetime(data["ë°œìƒì¼"])

            logger.info(f"âœ… ì²˜ë¦¬ëœ ë°ì´í„° í¬ê¸°: {len(data)} ê±´")
            flush_log(logger)

            return data

        except FileNotFoundError:
            logger.error(
                f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_config.csv_file_path}"
            )
            flush_log(logger)
            raise
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            flush_log(logger)
            raise

    def preprocess_text(self, text: str) -> List[str]:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (MeCab í˜•íƒœì†Œ ë¶„ì„)"""
        try:
            if not isinstance(text, str):
                return []
            nouns = self.mecab.nouns(text)
            return [
                noun
                for noun in nouns
                if noun not in self.korean_stop_words and len(noun) > 1
            ]
        except Exception as e:
            logger.warning(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {text[:20]}... - {e}")
            return []

    def save_data_incremental(
        self, new_data: pd.DataFrame, save_path: str = None
    ) -> None:
        """ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ ì €ì¥ (ë°ì´í„° ì¶•ì ìš©)"""
        if save_path is None:
            save_path = self.data_config.csv_file_path

        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            try:
                existing_data = pd.read_csv(save_path, encoding="utf-8")
                logger.info(f"ê¸°ì¡´ ë°ì´í„° ìˆ˜: {len(existing_data)} ê±´")
            except FileNotFoundError:
                existing_data = pd.DataFrame()
                logger.info("ìƒˆë¡œìš´ ë°ì´í„° íŒŒì¼ ìƒì„±")

            # ë°ì´í„° í•©ì¹˜ê¸°
            combined_data = pd.concat([existing_data, new_data], ignore_index=True)

            # ì¤‘ë³µ ì œê±° (í•„ìš”í•œ ê²½ìš°)
            combined_data = combined_data.drop_duplicates()

            # ì €ì¥
            combined_data.to_csv(save_path, index=False, encoding="utf-8")
            logger.info(
                f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(combined_data)} ê±´ (ìƒˆë¡œ ì¶”ê°€: {len(new_data)} ê±´)"
            )
            flush_log(logger)

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            flush_log(logger)
            raise


class GoogleSheetsLoader:
    """Google Sheets ë°ì´í„° ë¡œë”"""

    def __init__(self):
        self.service = None
        self._initialize_service()

    def _initialize_service(self):
        """Google Sheets ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            credentials = Credentials.from_service_account_file(
                sheets_config.service_account_file, scopes=sheets_config.scopes
            )
            self.service = build("sheets", "v4", credentials=credentials)
            logger.info("âœ… Google Sheets ì¸ì¦ ì„±ê³µ")
            flush_log(logger)
        except Exception as e:
            logger.error(f"âŒ Google Sheets ì¸ì¦ ì‹¤íŒ¨: {e}")
            flush_log(logger)
            raise

    def get_sheet_names(self, spreadsheet_id: str) -> List[str]:
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì˜ ì‹œíŠ¸ ì´ë¦„ ëª©ë¡ ì¡°íšŒ"""
        try:
            spreadsheet = (
                self.service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
            )
            sheets = [
                sheet["properties"]["title"] for sheet in spreadsheet.get("sheets", [])
            ]
            logger.info(f"âœ… ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì‹œíŠ¸ ì´ë¦„ ëª©ë¡: {sheets}")
            flush_log(logger)
            return sheets
        except Exception as e:
            logger.error(f"âŒ ì‹œíŠ¸ ì´ë¦„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            flush_log(logger)
            return []

    def count_models_from_sheet(
        self, spreadsheet_id: str, sheet_name: str, col_index: int = 3
    ) -> Counter:
        """ì‹œíŠ¸ì—ì„œ ëª¨ë¸ ì¹´ìš´íŠ¸ ì¶”ì¶œ"""
        try:
            # ì‹œíŠ¸ ì¡´ì¬ í™•ì¸
            sheet_names = self.get_sheet_names(spreadsheet_id)
            if sheet_name not in sheet_names:
                logger.error(
                    f"âŒ ì‹œíŠ¸ ì´ë¦„ '{sheet_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œíŠ¸: {sheet_names}"
                )
                flush_log(logger)
                raise ValueError(f"ì‹œíŠ¸ '{sheet_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # ë°ì´í„° ë²”ìœ„ ì„¤ì • (Dì—´, 3í–‰ë¶€í„° 1000í–‰ê¹Œì§€)
            sheet_range = f"{sheet_name}!D3:D1000"
            logger.info(f"âœ… ì‹œíŠ¸ ë²”ìœ„: {sheet_range}")
            flush_log(logger)

            # ë°ì´í„° ì¡°íšŒ
            result = (
                self.service.spreadsheets()
                .values()
                .get(spreadsheetId=spreadsheet_id, range=sheet_range)
                .execute()
            )

            values = result.get("values", [])
            if not values:
                logger.warning(f"âš ï¸ ì‹œíŠ¸ '{sheet_name}'ì—ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                flush_log(logger)
                raise ValueError(f"ì‹œíŠ¸ '{sheet_name}'ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ëª¨ë¸ëª… ì¶”ì¶œ ë° ì¹´ìš´íŠ¸
            models = [row[0].strip() for row in values if row and row[0].strip()]
            model_counts = Counter(models)

            logger.info(f"âœ… ëª¨ë¸ ì¹´ìš´íŠ¸ ì™„ë£Œ: {dict(model_counts)}")
            logger.info(f"ë°ì´í„° ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ): {models[:5]}")
            flush_log(logger)

            return model_counts

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì¹´ìš´íŠ¸ ì‹¤íŒ¨ (ì‹œíŠ¸: {sheet_name}): {e}")
            flush_log(logger)
            raise

    def get_monthly_production_counts(self) -> Dict[str, int]:
        """ì›”ê°„ ìƒì‚° ëª¨ë¸ ì¹´ìš´íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            logger.info("ğŸ“Š ì›”ê°„ ìƒì‚° ëª¨ë¸ ì¹´ìš´íŠ¸ ë¡œë“œ ì¤‘...")
            flush_log(logger)

            # ê¸°ë³¸ ì‹œíŠ¸ì—ì„œ ì‹œë„
            try:
                monthly_counts = dict(
                    self.count_models_from_sheet(
                        sheets_config.spreadsheet_id,
                        sheets_config.sheet_name,
                        col_index=3,
                    )
                )
                if monthly_counts:
                    return monthly_counts
            except Exception as e:
                logger.warning(f"ê¸°ë³¸ ì‹œíŠ¸ '{sheets_config.sheet_name}' ë¡œë“œ ì‹¤íŒ¨: {e}")

            # ëŒ€ì²´ ì‹œíŠ¸ì—ì„œ ì‹œë„
            logger.warning(
                f"âš ï¸ ì‹œíŠ¸ '{sheets_config.sheet_name}'ì—ì„œ ì‹¤íŒ¨. ëŒ€ì²´ ì‹œíŠ¸ '{sheets_config.fallback_sheet_name}' ì‹œë„."
            )
            flush_log(logger)

            monthly_counts = dict(
                self.count_models_from_sheet(
                    sheets_config.spreadsheet_id,
                    sheets_config.fallback_sheet_name,
                    col_index=3,
                )
            )

            if not monthly_counts:
                logger.error(
                    f"âš ï¸ ëŒ€ì²´ ì‹œíŠ¸ '{sheets_config.fallback_sheet_name}'ì—ì„œë„ ëª¨ë¸ ì¹´ìš´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
                )
                flush_log(logger)
                raise ValueError("ëª¨ë¸ ì¹´ìš´íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            return monthly_counts

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì¹´ìš´íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            flush_log(logger)
            raise
